# ๐ง ุฏุฑุงุณุฉ ููุงุฑูุฉ ูุงุฎุชูุงุฑ ูููุฐุฌ LLM ููุชูุญ ุงููุตุฏุฑ ูุชุทุจูู ุฏุฑุฏุดุฉ ุนูู Google Colab (CPU)

**ุงูุณูุงู**: ุจุญุซ ุนู ูููุฐุฌ ุดุจูู ChatGPT ููู ููุชูุญ ุงููุตุฏุฑ ูููุฏุฑ ูุดุชุบู ุนูู Google Colab CPU

---

## ุฃูููุง: ุฃูุถู 3 ููุฏููุงุช Open Source ูู ููุน ChatGPT (LLMs)

### ูู ูุฆุงุช ูุฎุชููุฉ:

| ุงููุฆุฉ | ุงูููุฏูู | ูุจุฐุฉ |
|--------|-------------|--------|
| ุงูุฐูุงุก ุงูุนุงูู | Mistral 7B Instruct | ููู ูู ุงููุญุงุฏุซุงุช ูุงูููุทู |
| ุงูุฎูุฉ ูุงูููุงุกุฉ | Phi-2 | ุงูุฐูุงุก ูุงูุณุฑุนุฉ ูุน ุญุฌู ุตุบูุฑ |
| ุงูุญุฌู ุงูุฃูู | TinyLLaMA 1.1B | ูุง ูุญุชุงุฌ RAM ุนุงูู |

---

## ุงูุณุคุงู: ูู ููุตุฏ meta-llama/Llama-3.2-1B-Instructุ

ุงูุฅุฌุงุจุฉ: ูุนู. ูุฐุง ูู ุงููููุฐุฌ ุงูุฐู ูููู ุชุดุบููู ูู ุจูุฆุงุช CPU ูุซู Google Colab.

---

## ุฃูุง ุจุงุณุชุฎุฏู Google Colab (CPU Mode)

ูุนูู ุงูุฃุณุงุณ ุฏู ุงุญุชุงุฌูุง ูููุฐุฌ:
- ุตุบูุฑ ุญุฌููุง
- ูุชูุงูู ูุน transformers
- ููููุน ุนููู LoRA ูุญูู ุงูููุงุฐุฌ ูุญููุง


---

## ุงูููุงุฑูุฉ ุงูููุงุฆูุฉ:

| ุงููููุฐุฌ                  | ุงูุญุฌู   | ุงูุฐูุงุก ุงูุนุงู | ุงูููุงุฑุฏ | ุงูุณุฑุนุฉ | ุงููุบุฉ ุงูุนุฑุจูุฉ | ููุงุท ููุฉ | ููุงุท ุถุนู |
|--------------------------|---------|------------------|----------------------|------------------|------------------------|---------------|--------------|
| LLaMA-3.2-1B-Instruct    | 1B      | ุฌูุฏ ุฌุฏูุง         | ุฎููู                 | ูุชูุณุท             | ููุจูู                 | ุญุฏูุซ โ ููุฌู Instruct | ูููู ุงูุชูุณูู |
| Phi-2                    | 1.7B    | ููุชุงุฒ ูู ุงูููุทู  | ุฎููู ุฌุฏูุง            | ุณุฑูุน              | ุถุนูู                  | ุฐูุงุก ุนุงูู | ูุง ูููู ุนุฑุจู |
| TinyLLaMA-1.1B           | 1.1B    | ูุชูุณุท            | ุฃุฎููู                | ุณุฑูุน ุฌุฏูุง         | ุถุนูู ุฌุฏูุง             | ููุชุงุฒ ููุชุนูู | ุงุณุชุฌุงุจุงุช ุณุทุญูุฉ |

---

## ูุชูุฌุฉ ุงูุงุฎุชูุงุฑ:

**meta-llama/Llama-3.2-1B-Instruct** ูู ุงูููุฏูู ุงููุฎุชุงุฑ ููุฃุณุจุงุจ ุงูุชุงููุฉ:

1. ููุงุณุจ ูู CPU
2. ูุจูู ุนูู LLaMA 3.2 ุงูุญุฏูุซ
3. ูุฏุฑุจ ุนูู ููุท Instruct
4. ููุฏู ุงุณุชุฌุงุจุงุช ุฐููุฉ ูููุฌูุฉ

---

## ุงูุชุฌุฑุจุฉ ุงูุฃููู

```python
!pip install transformers accelerate

from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# ุชุนุฑูู ุงููููุฐุฌ
model_id = "meta-llama/Llama-3.2-1B-Instruct"

# ุชุญููู ุงููููุฐุฌ
model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float32)
tokenizer = AutoTokenizer.from_pretrained(model_id)

prompt = "ุงุดุฑุญ ูู ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุจุทุฑููุฉ ูุจุณุทุฉ."
inputs = tokenizer(prompt, return_tensors="pt")
outputs = model.generate(**inputs, max_new_tokens=150)
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

---

## ุงุณุชูุชุงุฌ ููุงุฆู

ูู ุฎูุงู ูุฐู ุงูุฏุฑุงุณุฉ ุชู ุงููุตูู ุฅูู ุฃู ูููุฐุฌ **LLaMA-3.2-1B-Instruct** ูู ุงูุฎูุงุฑ ุงูุฃูุซู ููู ูุฎุชุงุฑ ุงูุชุทููุฑ ุนูู Google Colab CPU ุจุงููุฌุงู. ููููู ุชุทููุฑู ูุญููุง ูุชุฏุนูู ุงููุบุฉ ุงูุนุฑุจูุฉ ูุชุดุบููู ูุน ูุดุงุฑูุน ูุซู eyEar ูุบูุฑูุง.




## ๐ ุงููุตุงุฏุฑ ุงูุฃูุงุฏูููุฉ ูุงูุชูููุฉ ุงููุณุชุฎุฏูุฉ

### ๐ง LLaMA 3 1.2B Instruct - Meta
- Meta AI. (2024). *Introducing LLaMA 3 models*.  
  [https://ai.meta.com/blog/meta-llama-3](https://ai.meta.com/blog/meta-llama-3)

- Hugging Face model card for LLaMA 3 1.2B:  
  [https://huggingface.co/meta-llama/Llama-3-1.2B-Instruct](https://huggingface.co/meta-llama/Llama-3-1.2B-Instruct)

### ๐ ููุงุฑูุฉ ูุน TinyLLaMA
- TinyLLaMA: Hugging Face Model Card  
  [https://huggingface.co/cognitivecomputations/TinyLlama-1.1B-Chat-v1.0](https://huggingface.co/cognitivecomputations/TinyLlama-1.1B-Chat-v1.0)

- TinyLLaMA Paper (arXiv):  
  [https://arxiv.org/abs/2310.06825](https://arxiv.org/abs/2310.06825)

### โก ููุงุฑูุฉ ูุน Phi-2 - Microsoft
- Microsoft. (2023). *Phi-2: A Small Language Model with High Performance*.  
  [https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models)

- Hugging Face Model Card for Phi-2:  
  [https://huggingface.co/microsoft/phi-2](https://huggingface.co/microsoft/phi-2)

### ๐ Benchmarks & ููุงุฑูุงุช ุฃุฏุงุก
- Open LLM Leaderboard by Hugging Face:  
  [https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)

- LMSYS Chatbot Arena (ููุงุฑูุฉ ุญููููุฉ ุนุจุฑ ุงูุชุตููุช):  
  [https://chat.lmsys.org](https://chat.lmsys.org)

- Papers With Code - Leaderboards:  
  [https://paperswithcode.com/sota](https://paperswithcode.com/sota)


